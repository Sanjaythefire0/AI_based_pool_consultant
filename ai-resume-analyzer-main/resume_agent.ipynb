{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkylcj66865d",
        "outputId": "2a8c276d-517e-4c09-99dd-71e439b04a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytesseract, pypdfium2, pdf2image, pdfminer.six, pdfplumber\n",
            "Successfully installed pdf2image-1.17.0 pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0 pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "%pip install pdfplumber pytesseract pdf2image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxgAqAuP865e"
      },
      "outputs": [],
      "source": [
        "import pdfplumber\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbYV-I2e865e"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        # Try direct text extraction\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text\n",
        "\n",
        "        if text.strip():\n",
        "            return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Direct text extraction failed: {e}\")\n",
        "\n",
        "    # Fallback to OCR for image-based PDFs\n",
        "    print(\"Falling back to OCR for image-based PDF.\")\n",
        "    try:\n",
        "        images = convert_from_path(pdf_path)\n",
        "        for image in images:\n",
        "            page_text = pytesseract.image_to_string(image)\n",
        "            text += page_text + \"\\n\"\n",
        "    except Exception as e:\n",
        "        print(f\"OCR failed: {e}\")\n",
        "\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6gmBIby865f",
        "outputId": "204b93db-8ca0-44e7-ee28-af4de303d4cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracted Text from PDF:\n",
            "V Sanjay Kumar\n",
            "sanjk871@gmail.com |(+91)7604843643\n",
            "https://github.com/Sanjaythefire0 @sanjay-kumar620b1a1a1\n",
            "SKILLS\n",
            " Java\n",
            " Machine learning\n",
            " Python\n",
            " MySQL\n",
            " React JS\n",
            " Large Language Model’s\n",
            " Node JS\n",
            "EDUCATION\n",
            "❖ BTECH Artificial Intelligence | SRM University CGPA:9.21|2026\n",
            "❖ XII (CBSE) | Kendriya Vidyalaya AFS Tamabarm 76.4%|2022\n",
            "EXPERIENCE\n",
            "❖ Academic Research | Tamil Nadu Veterinary University\n",
            "Conducted a research project under Professor Dr. R. Venkataramanan at the\n",
            "Veterinary University of Tamil Nadu, utilizing the Folium library to create an interactive\n",
            "geospatial visualization of Pita bird distribution in a specific region.\n",
            "❖ Intel Unnati Industrial Training | Intel Corporation\n",
            "Performed sentiment analysis over reviews and comments of intel products.\n",
            "ACADEMIC PROJECTS\n",
            "❖ Crime detection from surveillance video footage\n",
            "This project will analyze videos and help us point out any crime or unusual activities in\n",
            "real-time using computer vision. This project uses roboflow,Yolo v8 and a customized\n",
            "neural network to process videos and make predictions.\n",
            "❖ Retail Store management using generative ai\n",
            "Developed using Langchain ,Stramlit(UI),MySQL(Database) that aims to manage and get\n",
            "insights about the huge items that is present in a retail inventory.\n",
            "❖ Bio Marker identification\n",
            "This project focuses on finding bio markers of a particular gene variant of CFTR gene\n",
            "which works effectively for that prescribed drug. This analytic project helped me bag a\n",
            "runner-up at life science innovation hosted by Agilisium Consulting.❖ Thinkify\n",
            "Thinkify is a vibrant space developed using React JS (Frontend),Node JS,Express and\n",
            "MongoDB for the database, where people from diverse backgrounds and interests\n",
            "joining our colege come together to engage in meaningful conversations, fostering an\n",
            "environment rich in idea exchange, knowledge sharing, and diverse experiences.\n",
            "ACHIEVEMENTS\n",
            "● Runner up at the life science innovation hackathon by Agilisium and Bversity\n",
            "● Secured second runner up at the case study presentation event hosted by Chennai\n",
            "Institute of Technology.\n",
            "CERTFICATIONS:\n",
            "• Completed programming in java certification provided by NPTEL.\n",
            "• Completed Computer Architecture certification provided by NPTEL.\n",
            "• Completed the ML Bootcamp certification provided by Udemy.\n",
            "• Completed Database Management Systems Certification by NPTEL\n",
            "• Completed Oracle AI foundation associate\n",
            "• Completed Foundation of Data science Program from CISCO Network Academy\n"
          ]
        }
      ],
      "source": [
        "pdf_path = \"/content/resuMeM.pdf\"\n",
        "resume_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "print(\"\\nExtracted Text from PDF:\")\n",
        "print(resume_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF6h9hHg865f"
      },
      "source": [
        "## Set Google GenerativeAI Api Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SngLGF5u865f",
        "outputId": "bb8c287a-eed0-458a-96e5-6779e0f09cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google.generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (2.177.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google.generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google.generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google.generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google.generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google.generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google.generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google.generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google.generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google.generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google.generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google.generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google.generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2025.7.14)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.1\n"
          ]
        }
      ],
      "source": [
        "%pip install google.generativeai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C45yzg7v865f"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "genai.configure(api_key=(\"AIzaSyAU-PvPRXFTlR1w0WXBurTus4sBofJlFj8\"))\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "8iEa3jA4865f",
        "outputId": "b019c18c-d151-4656-9a98-c69db06abded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of India is **New Delhi**.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = model.generate_content(\"What is the capital of India?\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QR4gWL_865f",
        "outputId": "683e25eb-ae85-4b11-9630-50d1a8f61850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response:\n",
            "GenerateContentResponse(\n",
            "    done=True,\n",
            "    iterator=None,\n",
            "    result=protos.GenerateContentResponse({\n",
            "      \"candidates\": [\n",
            "        {\n",
            "          \"content\": {\n",
            "            \"parts\": [\n",
            "              {\n",
            "                \"text\": \"The capital of India is **New Delhi**.\\n\"\n",
            "              }\n",
            "            ],\n",
            "            \"role\": \"model\"\n",
            "          },\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"avg_logprobs\": -0.0009367600083351135\n",
            "        }\n",
            "      ],\n",
            "      \"usage_metadata\": {\n",
            "        \"prompt_token_count\": 7,\n",
            "        \"candidates_token_count\": 10,\n",
            "        \"total_token_count\": 17\n",
            "      },\n",
            "      \"model_version\": \"gemini-1.5-flash\"\n",
            "    }),\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osDwGD8r865g",
        "outputId": "d73cf6f6-aae9-4321-f759-d76cc3a53117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of India is **New Delhi**.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcwsaZjy865g"
      },
      "outputs": [],
      "source": [
        "def analyze_resume(resume_text, job_description=None):\n",
        "    if not resume_text:\n",
        "        return {\"error\": \"Resume text is required for analysis.\"}\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    base_prompt = f\"\"\"\n",
        "    You are an experienced HR with Technical Experience in the field of any one job role from Data Science, Data Analyst, DevOPS, Machine Learning Engineer, Prompt Engineer, AI Engineer, Full Stack Web Development, Big Data Engineering, Marketing Analyst, Human Resource Manager, Software Developer your task is to review the provided resume.\n",
        "    Please share your professional evaluation on whether the candidate's profile aligns with the role.ALso mention Skills he already have and siggest some skills to imorve his resume , alos suggest some course he might take to improve the skills.Highlight the strengths and weaknesses.\n",
        "\n",
        "    Resume:\n",
        "    {resume_text}\n",
        "    \"\"\"\n",
        "\n",
        "    if job_description:\n",
        "        base_prompt += f\"\"\"\n",
        "        Additionally, compare this resume to the following job description:\n",
        "\n",
        "        Job Description:\n",
        "        {job_description}\n",
        "\n",
        "        Highlight the strengths and weaknesses of the applicant in relation to the specified job requirements.\n",
        "        \"\"\"\n",
        "\n",
        "    response = model.generate_content(base_prompt)\n",
        "\n",
        "    analysis = response.text.strip()\n",
        "    return analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Wqhhnq7E865g",
        "outputId": "1ca62b65-8131-40e7-9bdf-f7a8557e05ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Resume Evaluation for a Data Science/AI Engineering Role\n",
            "\n",
            "This resume belongs to V Sanjay Kumar, a final-year B.Tech student in Artificial Intelligence.  As an experienced HR professional with a background in Data Science, I've reviewed his application and offer the following evaluation:\n",
            "\n",
            "\n",
            "**Strengths:**\n",
            "\n",
            "* **Strong Foundation:** Sanjay possesses a solid foundation in programming (Java, Python), databases (MySQL), and frontend development (ReactJS). His academic background in AI is relevant to many data science roles.\n",
            "* **Relevant Projects:** His projects demonstrate practical application of skills:  Sentiment analysis, geospatial visualization, computer vision for crime detection, retail management using generative AI, and biomarker identification showcase diverse skillsets and problem-solving abilities. The Thinkify project highlights his full-stack development capabilities.\n",
            "* **Achievements:**  Placing in hackathons and case study competitions demonstrates his competitive spirit and ability to deliver results under pressure.\n",
            "* **Certifications:**  Certifications from reputable sources (NPTEL, Udemy, Cisco, Oracle) add credibility and demonstrate commitment to continuous learning.\n",
            "\n",
            "\n",
            "**Weaknesses:**\n",
            "\n",
            "* **Resume Structure and Clarity:**  The resume lacks a clear, concise summary or objective statement at the beginning.  The project descriptions are too brief and lack quantifiable results. The bullet points for achievements need expansion and more context. For example, instead of \"Runner up at the life science innovation hackathon,\" state the problem solved, your contribution, and the impact (e.g., \"Developed a biomarker identification model for CFTR gene variants, achieving a runner-up position in the Agilisium and Bversity Life Science Innovation Hackathon, improving accuracy by X%\").\n",
            "* **Experience Section:** The \"Academic Research\" experience, while valuable, could be stronger with more detail on the methodology, results, and contributions.  The Intel Unnati internship needs more detail on the tools used, the size of the dataset, and the impact of the sentiment analysis.\n",
            "* **Lack of Specific Data Science Skills:** While he lists \"Machine Learning,\" the resume lacks demonstrable expertise in specific techniques (e.g., regression, classification, clustering, deep learning architectures).  He should highlight specific algorithms or models used in his projects.\n",
            "* **Missing Portfolio Link:** While a GitHub profile is mentioned, a direct link to a portfolio showcasing his projects would be highly beneficial.\n",
            "\n",
            "\n",
            "**Skills:**\n",
            "\n",
            "**Existing Skills:**\n",
            "\n",
            "* Programming: Java, Python, Node.js, React.js\n",
            "* Databases: MySQL, MongoDB\n",
            "* Machine Learning Fundamentals\n",
            "* Data Visualization (Folium)\n",
            "* Full-Stack Web Development\n",
            "* Large Language Models (LLMs) – This needs further elaboration on his proficiency level and practical experience.\n",
            "* Computer Vision (YOLOv8)\n",
            "\n",
            "\n",
            "**Skills to Improve:**\n",
            "\n",
            "* **Advanced Machine Learning Techniques:** Deep learning (CNNs, RNNs, Transformers), model deployment, model evaluation metrics, hyperparameter tuning.\n",
            "* **Data Wrangling and Preprocessing:** Expertise in cleaning, transforming, and preparing data for modeling.\n",
            "* **Big Data Technologies:** Spark, Hadoop (relevant if aiming for big data roles).\n",
            "* **Cloud Computing:** AWS, Azure, GCP (highly desirable for many data science roles).\n",
            "* **Version Control:**  Showcases the use of Git and GitHub effectively within projects.\n",
            "* **Communication and Presentation Skills:**  Further developing ability to clearly articulate technical details to both technical and non-technical audiences.\n",
            "\n",
            "\n",
            "**Course Suggestions:**\n",
            "\n",
            "* **Advanced Machine Learning Specialization (Coursera/edX):** To deepen his knowledge of specific ML algorithms and techniques.\n",
            "* **Deep Learning Specialization (Coursera):**  Focuses on neural networks and deep learning architectures.\n",
            "* **Data Wrangling with Python (DataCamp/Coursera):**  Develop skills in data cleaning and preprocessing.\n",
            "* **Cloud Computing Fundamentals (AWS/Azure/GCP):**  Learn the basics of cloud platforms and their services.\n",
            "* **Big Data Technologies (Coursera/edX/Udacity):** If interested in big data roles.\n",
            "* **Effective Communication for Data Scientists (Coursera/Udacity):**  To enhance presentation and storytelling skills.\n",
            "\n",
            "\n",
            "**Overall Alignment with Role:**\n",
            "\n",
            "Sanjay's profile shows promise but needs strengthening to align fully with most data science/AI engineering roles.  His projects demonstrate some capabilities, but the lack of depth in specific techniques and the insufficient detail in his resume hold him back.  By improving the resume's structure, adding quantifiable results to his projects, and acquiring additional skills through coursework, he can significantly improve his chances of securing a suitable role.  For internships or entry-level positions, his existing skills and projects are a good start.  However, for more senior positions, further skill development and experience will be necessary.\n"
          ]
        }
      ],
      "source": [
        "print(analyze_resume(resume_text))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}